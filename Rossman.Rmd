---
title: "Rossman Output"
author: "Ashish Dalal"
date: "21 November 2015"
output: word_document
---
```{r}
#setting the working directory to be home directory prior to beginning 
setwd("~/Desktop/Projects/Rossman/")

#loading important libraries for data analysis ahead
library(readr) 
library(dplyr) 
library(ggplot2) 
library(caret) 
library(randomForest)

#reading the training data
training_data <- read.csv("train.csv")

#looking at structure and first few entries of training data
str(training_data)
dim(training_data)
head(training_data,2)

#getting descriptive statistics for train dataa
summary(training_data)

#reading the testing data
testing_data <- read.csv("test.csv")

#looking at structure and first few entries of testing data
str(testing_data)
dim(testing_data)
head(testing_data,2)

#getting descriptive statistics for test data
summary(testing_data)

#looking store data information
store_data <- read.csv("store.csv")
str(store_data)
dim(store_data)
head(store_data,2)

#getting descriptive statistics for store data
summary(store_data)

#looking at sample_submission 
sample_submission <- read.csv("sample_submission.csv")
str(sample_submission)
dim(sample_submission)
head(sample_submission,2)

#Preprocessing with training data

#attaching the data sets to be used to directly refer to their column names
attach(training_data)
attach(testing_data)
attach(store_data)

#converting Store, DayOfWeek, Open, Promo, SchoolHoliday variables into factor 
#variables as it does not make sense to treat them as integers in further analysis.

#factorization with training data
training_data$Store <- as.factor(training_data$Store)
training_data$DayOfWeek <- as.factor(training_data$DayOfWeek)
training_data$Open <- as.factor(training_data$Open)
training_data$Promo <- as.factor(training_data$Promo)
training_data$SchoolHoliday <- as.factor(training_data$SchoolHoliday)



#factorization with testing data set
testing_data$Id <- as.factor(testing_data$Id)
testing_data$Store <- as.factor(testing_data$Store)
testing_data$DayOfWeek <- as.factor(testing_data$DayOfWeek)
testing_data$Open <- as.factor(testing_data$Open)
testing_data$Promo <- as.factor(testing_data$Promo)
testing_data$SchoolHoliday <- as.factor(testing_data$SchoolHoliday)

#factorization with store data
store_data$Store <- as.factor(store_data$Store)
store_data$CompetitionDistance <- as.numeric(store_data$CompetitionDistance)
store_data$Promo2 <- as.factor(store_data$Promo2)
store_data$PromoInterval <- as.factor(store_data$PromoInterval)


#Factorization ends for all datasets, just checking if indeed has been done,
#let's check the structure of all three datasets
str(training_data)
str(testing_data)
str(store_data)

#Note : We can see that there are no customers in testing dataset
#Now we split date column of both testing and training datasets into three separate columns
#for day, month and year respectively, for increasing our predictors for better learning from
#data
training_data$Date <- as.Date(training_data$Date)
training_data <- within(training_data, {
  year <- as.integer(format(training_data$Date, "%Y"))
  month <- as.integer(format(training_data$Date, "%m"))
  day <- as.integer(format(training_data$Date, "%d"))
})

testing_data$Date <- as.Date(testing_data$Date)
testing_data <- within(testing_data, {
  year <- as.integer(format(testing_data$Date, "%Y"))
  month <- as.integer(format(testing_data$Date, "%m"))
  day <- as.integer(format(testing_data$Date, "%d"))
})

#Refactorizing training and test datasets again
training_data$month <- as.factor(training_data$month)
training_data$day <- as.factor(training_data$day)
training_data$year <- as.factor(training_data$year)
testing_data$month <- as.factor(testing_data$month)
testing_data$day <- as.factor(testing_data$day)
testing_data$year <- as.factor(testing_data$year)

#we now, drop down date variable as have already captured it's information separately in day, month and year respectively
testing_data <- within(testing_data,rm(Date))

#Now, we also drop Date column from training_data for similar reasons as was the case with testing data
training_data <- within(training_data,rm(Date))

#getting descriptive stats for both training and testing datasets
summary(training_data)
summary(testing_data) 

#Important Observations
#Observation:1 We see here that testing data does not have representation of b and c factor levels in
#the StateHoliday variable.
#Observation 2: Test data has 11 NA's under the Open variable where as training data has none

#Now, let us check out the stores where these NA's are occuring
testing_data[is.na(Open),]
#We see that missing data for Open is only at Store number 622.
#Since we have missing data here, we want to account for this missing data and fill these 
#NA values with some meaningful replacement. So, let us checkout on what all days do the Store 622
#open
subset(testing_data,(testing_data$Store == 622 & testing_data$Open == 1))
#So we see that except on Day 7, which happens to be a Sunday,Store 622 is open on all days.
#Now, let us also check Store 622 data in the training set
subset(training_data,(training_data$Store == 622))
#So, we see here in training data too, that except Sunday, in most cases
#Store 622 has been open on all days of week.
#So, it makes sense to impute the NA's for Store 622 by putting 1 under Open variable in place of NA
testing_data$Open[is.na(testing_data$Open)] <- 1
#Now, let us checkback if indeed we have now finished the imputations and removed all NA's
subset(testing_data,(testing_data$Store == 622))

#Now, we go for merging the data
training_data <- merge(training_data,store_data)
testing_data <- merge(testing_data,store_data)

#After merging the data, let us look at the structure and description of data once again.
str(training_data)
str(testing_data)
dim(training_data)
dim(testing_data)
summary(training_data)
summary(testing_data)
str(testing_data)

#So, let us start the investigation and prediction on trivial cases

#checking out sale statistics for each store on training data
dplyr::summarise(dplyr::group_by(training_data,Store),average_sales = mean(Sales),max_sale = max(Sales), stdev_sales=sd(Sales))

#checking out monthly and yearly sale statistics for each store on training data
dplyr::summarise(dplyr::group_by(training_data,Store,month),average_sales = mean(Sales),max_sale = max(Sales), stdev_sales=sd(Sales) )
dplyr::summarise(dplyr::group_by(training_data,Store,year),average_sales = mean(Sales),max_sale = max(Sales), stdev_sales=sd(Sales) )

#checking out state holiday sales statistics for each store on training data
dplyr::summarise(dplyr::group_by(training_data,Store,StateHoliday),average_sales = mean(Sales),max_sale = max(Sales), stdev_sales=sd(Sales) )

#to arrive at a conclusion, we will have to dig a little deeper, so we check out
#number of state holidays of each type for each store in training data
base::table(training_data$Store,training_data$StateHoliday)

#Remember, our observation 1, that we saw in the beginning in the test set
#Hence, we attach importance on sales statistics corresponding to state holiday
#level of "a"
a_holiday_sales <- dplyr::summarise(dplyr::group_by(select(filter(training_data,StateHoliday == "a"),Store,Sales),Store),max_sale = max(Sales))

#So, we can see a lot of stores have zero sales on "a" state holidays.
#finding out stores for which max sale is zero on "a" state holidays.
a_zero_sale_stores <- dplyr::filter(a_holiday_sales,a_holiday_sales$max_sale == 0)
dim(a_zero_sale_stores)

#so in testing data, for above stores on "a" state holidays, we predict zero sales
#so, first we find all stores in testing data for which "a" state holidays are applicable
a_test_stores <- dplyr::select(dplyr::filter(testing_data,testing_data$StateHoliday == "a"),Store)
dim(a_test_stores)

#find matching stores for zero sales prediction
a_match <- base::intersect(as.integer(as.vector(a_zero_sale_stores$Store)),as.integer(as.vector(a_test_stores$Store)))
int_test_stores <- as.integer(testing_data$Store)
for(i in 1:nrow(testing_data)){
 for(j in 1:length(a_match)){
    if(int_test_stores[i] == a_match[j] & testing_data$StateHoliday[i] == "a"){
      testing_data$Sales[i] <- 0
    }
  }
}


#checking out school holiday sales statistics for each store on training data
dplyr::summarise(dplyr::group_by(training_data,Store,SchoolHoliday),average_sales = mean(Sales),max_sale = max(Sales), stdev_sales=sd(Sales) )
#As expected that people or better, school folks would flock to stores for shopping,
#we can see increased sales on school holidays. 

#checking which store is open on which days
base::table(training_data$Store,training_data$Open)
base::prop.table(base::table(training_data$Store,training_data$Open),1)*100
#this means most of the stores are closed for almost 16-17% during the operational
#period where as they are open for about 82-83% during the operational period

#checking sales statistics on open/closed days for each store on training data
dplyr::summarise(dplyr::group_by(training_data,Store,Open),average_sales = mean(Sales),max_sale = max(Sales), stdev_sales=sd(Sales) )
#We can see that on closed days, for each of the stores in the training data the sale recorded was zero.
#So, to begin with predictive thinking, we can safely predict a zero sale for all closed days.

testing_data$Sales[testing_data$Open == 0] <- 0

#checking sales statistics on promo days for each store in training data
dplyr::summarise(dplyr::group_by(training_data,Store,Promo),average_sales = mean(Sales),max_sale = max(Sales), stdev_sales=sd(Sales) )
#As expected, sales figures on promo days are higher than on days when promotions don't run
```



